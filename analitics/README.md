[![Guide for launch](https://img.shields.io/badge/Guide-for_launch-5F9EA0.svg)](guide_for_launch.md)

## Исследовательский анализ данных

Мы провели **исследовательский анализ данных** на основе датасета *PubMed*.

### 1. На каких языках написаны статьи?

Мы обработали весь зарубежный датасет _PubMed_ с помощью функции ___nltk.tokenize.sent_tokenize___, которая разделила датасет на логические предложения. Затем мы выявили наиболее доминирующие кластеры языков с помощью ___langdetect.detect_langs___. Полученные кластеры языков были визуализированы, и мы получили график распространённости:

![График распространения языков](image.png)

По графику мы пришли к выводу:

> *PubMed — это зарубежный источник информации*. Люди публикуют на международном языке (английском), так как он создан с поддержкой *Национальной медицинской библиотеки США*. Исходя из этого, видно, что очень много литературы написано на английском языке. Также это международная библиотека, в которую можно выставить статью без каких-либо ограничений на народности и национальность, поэтому мы видим такой разброс языков от *чешского* до *немецкого и французского*.

### 2. Какие тематики можно выделить?

Для нахождения тематик мы решили разделить текст на кластеры. Однако после тестов *ни одна модель* не смогла нормально разделить и различить эти кластеры. В итоге мы решили взять статьи, разбить их на вектора с помощью ___sklearn.feature_extraction.text.TfidfVectorizer___ и сравнить вектора статей с векторами тем, используя косинусное сходство ___sklearn.metrics.pairwise.cosine_similarity___. Затем мы отсортировали сходства и выбрали 10 самых лучших, получив следующий график:

![График распространения тем](image-1.png)

> На графике видно очень **сильное разделение и разнообразие тем**. Больше всего тем по системам и контролю, а также по тканям и органам. PubMed нацелен на биомедицинские исследования, из этого и следует, что в нём находится очень много публикаций про *ткани и органы*, а также обработку больших данных в сфере *биомедицины*.

### 3. Какие проблемы есть в данных?

В данном датасете достаточно много проблем:

1. **Неправильное написание знаков препинания**: Пробелы перед запятыми и точками (например, **пробел запятая пробел** и **пробел точка пробел**) мешают корректному определению смысловых предложений с помощью ___nltk.sentence___.

2. **Пустые строки**: Это одна из самых неприятных проблем в датасетах. Пустые строки могут приводить к ошибкам, когда вы пытаетесь пройтись по датасету, вызывая ошибку **обращение к несуществующему объекту**.

3. **Переносы строк (`\n`)**: Эта часть данных также требует внимания. Переносы строк используются не по назначению и могут стоять в начале текста, что приводит к хаосу в данных.
